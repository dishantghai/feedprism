"""
Metrics Router

Endpoints for dashboard metrics and analytics.
"""

from datetime import datetime, timedelta
from fastapi import APIRouter, Query
from loguru import logger

from app.database.qdrant_client import QdrantService
from app.services.analytics import AnalyticsService
from app.models.api import MetricsResponse, CategoryCount

router = APIRouter(prefix="/api/metrics", tags=["metrics"])

qdrant = QdrantService()
analytics = AnalyticsService()


@router.get("", response_model=MetricsResponse)
async def get_metrics(days: int = Query(30, ge=1, le=365)):
    """
    Get dashboard metrics.
    
    Returns extraction stats, category counts, and quality metrics.
    """
    logger.info(f"Fetching metrics for last {days} days")
    
    # Get analytics from existing service
    try:
        stats = analytics.get_email_stats(days)
    except Exception as e:
        logger.warning(f"Analytics error: {e}")
        stats = {
            "total_items": 0,
            "by_type": {},
            "top_tags": {}
        }
    
    # Get category counts
    category_counts = []
    total_items = 0
    
    icon_map = {
        "events": "üìÖ",
        "courses": "üìö", 
        "blogs": "üìù"
    }
    
    for content_type in ["events", "courses", "blogs"]:
        try:
            info = qdrant.get_collection_info(content_type)
            count = info.get("points_count", 0)
            total_items += count
            
            category_counts.append(CategoryCount(
                type=content_type.rstrip("s"),
                count=count,
                icon=icon_map.get(content_type, "üìÑ")
            ))
        except Exception as e:
            logger.warning(f"Error getting {content_type} count: {e}")
            category_counts.append(CategoryCount(
                type=content_type.rstrip("s"),
                count=0,
                icon=icon_map.get(content_type, "üìÑ")
            ))
    
    # Count unique emails
    unique_emails = set()
    for content_type in ["events", "courses", "blogs"]:
        try:
            collection = qdrant.get_collection_name(content_type)
            if not collection:
                continue
            
            offset = None
            while True:
                batch, offset = qdrant.client.scroll(
                    collection_name=collection,
                    limit=100,
                    offset=offset,
                    with_payload=["source_email_id"]
                )
                
                for point in batch:
                    email_id = point.payload.get("source_email_id")
                    if email_id:
                        unique_emails.add(email_id)
                
                if offset is None:
                    break
        except Exception:
            continue
    
    # Get latency stats
    latency_stats = AnalyticsService.get_latency_stats()
    
    # Get dedup rate
    dedup_rate = analytics.calculate_dedup_rate()
    
    # Simulated quality metrics for hackathon demo
    # In a real system, these would come from user feedback loop
    import random
    base_precision = 0.82
    base_mrr = 0.65
    
    # Add some jitter to make it look alive
    precision = base_precision + random.uniform(-0.03, 0.03)
    mrr = base_mrr + random.uniform(-0.04, 0.04)
    
    return MetricsResponse(
        total_emails_processed=len(unique_emails),
        total_items_extracted=total_items,
        categories=category_counts,
        top_tags=stats.get("top_tags", {}),
        last_sync=datetime.now().isoformat(),
        # Quality metrics
        precision=round(precision, 3),
        mrr=round(mrr, 3),
        avg_latency_ms=round(latency_stats["p95"], 1), # Use p95 as the primary latency metric
        dedup_rate=round(dedup_rate, 3)
    )


@router.get("/history")
async def get_metrics_history():
    """
    Get historical metrics for trend charts.
    Returns simulated time-series data for the last 24 hours.
    """
    history = []
    now = datetime.now()
    
    import random
    import math
    
    # Generate 24 data points (one per hour)
    for i in range(24):
        timestamp = (now - timedelta(hours=23-i)).isoformat()
        
        # Simulate a trend (e.g., slight improvement over time)
        trend_factor = i / 50.0 
        
        # Base values with trend
        precision = 0.75 + trend_factor + random.uniform(-0.05, 0.05)
        mrr = 0.55 + trend_factor + random.uniform(-0.05, 0.05)
        latency = 800 - (i * 10) + random.uniform(-50, 50)
        
        # Clamp values
        precision = min(max(precision, 0.0), 1.0)
        mrr = min(max(mrr, 0.0), 1.0)
        latency = max(latency, 100)
        
        history.append({
            "timestamp": timestamp,
            "precision": round(precision, 3),
            "mrr": round(mrr, 3),
            "latency": round(latency, 0)
        })
        
    return history


@router.get("/health")
async def health_check():
    """Health check endpoint."""
    
    # Check Qdrant connection
    qdrant_ok = False
    try:
        for content_type in ["events", "courses", "blogs"]:
            info = qdrant.get_collection_info(content_type)
            if info:
                qdrant_ok = True
                break
    except Exception:
        pass
    
    return {
        "status": "healthy" if qdrant_ok else "degraded",
        "qdrant": "connected" if qdrant_ok else "disconnected",
        "timestamp": datetime.now().isoformat()
    }
