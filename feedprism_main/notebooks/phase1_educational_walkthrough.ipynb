{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: Core Pipeline - Educational Walkthrough\n",
        "\n",
        "This notebook walks through the complete Phase 1 pipeline step-by-step.\n",
        "\n",
        "**What you'll learn:**\n",
        "1. How to fetch emails from Gmail API\n",
        "2. How to parse HTML newsletters\n",
        "3. How to extract events using LLMs\n",
        "4. How to generate embeddings\n",
        "5. How to store in Qdrant vector database\n",
        "6. How to search semantically\n",
        "\n",
        "**Prerequisites:**\n",
        "- Phase 0 complete (environment setup)\n",
        "- Gmail OAuth configured\n",
        "- Qdrant running in Docker\n",
        "- OpenAI API key set in `.env`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Import Libraries and Initialize\n",
        "\n",
        "First, let's import all the modules we'll need and set up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import sys\n",
        "import json\n",
        "import os\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# IMPORTANT: Change working directory to project root\n",
        "# This ensures credentials.json and token.json are found correctly\n",
        "project_root = Path('/Users/Shared/ALL WORKSPACE/Hackathons/mom_hack/feedprism_main')\n",
        "os.chdir(project_root)\n",
        "print(f\"\ud83d\udcc1 Working directory: {os.getcwd()}\")\n",
        "\n",
        "# Add project root to Python path\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Third-party imports\n",
        "import asyncio\n",
        "from loguru import logger\n",
        "\n",
        "# Our custom modules (we'll build these step by step)\n",
        "from app.config import settings\n",
        "from app.services.gmail_client import GmailClient\n",
        "from app.services.parser import EmailParser\n",
        "from app.services.extractor import LLMExtractor\n",
        "from app.services.embedder import EmbeddingService\n",
        "from app.database.qdrant_client import QdrantService\n",
        "from app.models.extraction import ExtractedEvent, EventExtractionResult\n",
        "\n",
        "# Configure logger for notebook\n",
        "logger.remove()  # Remove default handler\n",
        "logger.add(sys.stdout, level=\"INFO\", format=\"<level>{level: <8}</level> | {message}\")\n",
        "\n",
        "print(\"\u2705 All imports successful!\")\n",
        "print(f\"\ud83d\udcc1 Project root: {project_root}\")\n",
        "print(f\"\ud83d\udd11 Credentials path: {settings.gmail_credentials_path}\")\n",
        "print(f\"\ud83c\udfab Token path: {settings.gmail_token_path}\")\n",
        "print(f\"\ud83d\udd27 Config loaded: OpenAI key = {'***' + settings.openai_api_key[-4:]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Fetch Emails from Gmail\n",
        "\n",
        "**What's happening:**\n",
        "- We connect to Gmail API using OAuth credentials\n",
        "- Search for content-rich emails (newsletters, events)\n",
        "- Fetch full email content including HTML body\n",
        "\n",
        "**Key concepts:**\n",
        "- Gmail API uses labels and search queries\n",
        "- Emails have multipart structure (text + HTML)\n",
        "- We prefer HTML for newsletters (richer content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Gmail client\n",
        "# This will:\n",
        "# 1. Load OAuth credentials from token.json\n",
        "# 2. Refresh token if expired\n",
        "# 3. Connect to Gmail API\n",
        "gmail_client = GmailClient()\n",
        "\n",
        "print(\"\u2705 Gmail client initialized\")\n",
        "print(\"\\n\ud83d\udce7 Fetching emails...\")\n",
        "\n",
        "# Fetch content-rich emails from last 7 days\n",
        "# Parameters:\n",
        "#   days_back: How far back to search\n",
        "#   max_results: Maximum emails to fetch\n",
        "emails = gmail_client.fetch_content_rich_emails(\n",
        "    days_back=7,\n",
        "    max_results=5  # Start with just 5 for this demo\n",
        ")\n",
        "\n",
        "print(f\"\\n\u2705 Fetched {len(emails)} emails\")\n",
        "\n",
        "# Let's examine the first email\n",
        "if emails:\n",
        "    first_email = emails[0]\n",
        "    print(\"\\n\ud83d\udcec First Email Details:\")\n",
        "    print(f\"  Subject: {first_email['subject']}\")\n",
        "    print(f\"  From: {first_email['from']}\")\n",
        "    print(f\"  Date: {first_email['date']}\")\n",
        "    print(f\"  Has HTML: {first_email['body_html'] is not None}\")\n",
        "    print(f\"  HTML Length: {len(first_email['body_html']) if first_email['body_html'] else 0} characters\")\n",
        "    print(f\"  Snippet: {first_email['snippet'][:100]}...\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f No emails found. Try adjusting search criteria.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Parse HTML Email\n",
        "\n",
        "**What's happening:**\n",
        "- Take raw HTML from email\n",
        "- Remove tracking pixels, scripts, styles\n",
        "- Convert to clean text while preserving structure\n",
        "- Extract all links\n",
        "\n",
        "**Why this matters:**\n",
        "- Newsletters have complex HTML with inline CSS\n",
        "- Tracking pixels and ads add noise\n",
        "- Clean text is better for LLM extraction\n",
        "- Links contain important registration/info URLs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize HTML parser\n",
        "# This uses BeautifulSoup4 + html2text\n",
        "parser = EmailParser()\n",
        "\n",
        "print(\"\u2705 Email parser initialized\")\n",
        "\n",
        "# Parse the first email's HTML\n",
        "if emails and emails[0]['body_html']:\n",
        "    print(\"\\n\ud83d\udd0d Parsing HTML...\")\n",
        "    \n",
        "    parsed_result = parser.parse_html_email(emails[0]['body_html'])\n",
        "    \n",
        "    print(f\"\\n\u2705 Parsing complete!\")\n",
        "    print(f\"\\n\ud83d\udcc4 Results:\")\n",
        "    print(f\"  Title: {parsed_result['title']}\")\n",
        "    print(f\"  Clean text length: {len(parsed_result['text'])} characters\")\n",
        "    print(f\"  Links extracted: {len(parsed_result['links'])}\")\n",
        "    \n",
        "    # Show first few links\n",
        "    print(f\"\\n\ud83d\udd17 Sample Links:\")\n",
        "    for i, link in enumerate(parsed_result['links'][:3], 1):\n",
        "        print(f\"  {i}. {link['text'][:50]}... \u2192 {link['url'][:60]}...\")\n",
        "    \n",
        "    # Show preview of clean text\n",
        "    print(f\"\\n\ud83d\udcdd Clean Text Preview (first 500 chars):\")\n",
        "    print(\"-\" * 70)\n",
        "    print(parsed_result['text'][:500])\n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    # Store for next step\n",
        "    clean_text = parsed_result['text']\n",
        "    email_subject = emails[0]['subject']\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f No HTML body to parse\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Extract Events with LLM\n",
        "\n",
        "**What's happening:**\n",
        "- Send clean text to OpenAI GPT-4o-mini\n",
        "- Use structured output (JSON Schema) for guaranteed valid JSON\n",
        "- Extract event details: title, date, location, link, etc.\n",
        "- Get confidence score\n",
        "\n",
        "**How structured output works:**\n",
        "1. We define a Pydantic model (ExtractedEvent)\n",
        "2. Pydantic generates JSON Schema\n",
        "3. OpenAI guarantees response matches schema\n",
        "4. No parsing errors or invalid JSON!\n",
        "\n",
        "**Note:** This step requires OpenAI API key and will make an API call (~$0.0003 per email)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize LLM extractor\n",
        "# This creates an async OpenAI client\n",
        "extractor = LLMExtractor()\n",
        "\n",
        "print(\"\u2705 LLM extractor initialized\")\n",
        "print(f\"   Model: {extractor.model}\")\n",
        "print(f\"   Temperature: {extractor.temperature} (0 = deterministic)\")\n",
        "\n",
        "# Extract events from the parsed text\n",
        "# This is an async function, so we need to use await\n",
        "print(\"\\n\ud83e\udd16 Extracting events with LLM...\")\n",
        "print(\"   (This may take 2-4 seconds)\")\n",
        "\n",
        "# Run async extraction\n",
        "extraction_result = await extractor.extract_events(\n",
        "    email_text=clean_text,\n",
        "    email_subject=email_subject\n",
        ")\n",
        "\n",
        "print(f\"\\n\u2705 Extraction complete!\")\n",
        "print(f\"\\n\ud83d\udcca Results:\")\n",
        "print(f\"  Events found: {len(extraction_result.events)}\")\n",
        "print(f\"  Confidence: {extraction_result.confidence:.2f} (0.0 - 1.0)\")\n",
        "\n",
        "# Display each extracted event\n",
        "if extraction_result.events:\n",
        "    print(f\"\\n\ud83c\udf89 Extracted Events:\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    for i, event in enumerate(extraction_result.events, 1):\n",
        "        print(f\"\\nEvent {i}:\")\n",
        "        print(f\"  \ud83d\udccc Title: {event.title}\")\n",
        "        print(f\"  \ud83d\udcdd Description: {event.description[:100] if event.description else 'N/A'}...\")\n",
        "        print(f\"  \ud83d\udcc5 Start Time: {event.start_time or 'Not specified'}\")\n",
        "        print(f\"  \ud83d\udd52 Timezone: {event.timezone or 'Not specified'}\")\n",
        "        print(f\"  \ud83d\udccd Location: {event.location or 'Not specified'}\")\n",
        "        print(f\"  \ud83d\udd17 Registration: {event.registration_link or 'Not specified'}\")\n",
        "        print(f\"  \ud83d\udcb0 Cost: {event.cost or 'Not specified'}\")\n",
        "        print(f\"  \ud83c\udfe2 Organizer: {event.organizer or 'Not specified'}\")\n",
        "        print(f\"  \ud83c\udff7\ufe0f  Tags: {', '.join(event.tags) if event.tags else 'None'}\")\n",
        "        print(f\"  \u23f0 Status: {event.compute_status().value}\")\n",
        "    \n",
        "    print(\"=\" * 70)\n",
        "else:\n",
        "    print(\"\\n\u26a0\ufe0f No events found in this email\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Generate Embeddings\n",
        "\n",
        "**What's happening:**\n",
        "- Convert event text to dense vector (384 dimensions)\n",
        "- Use sentence-transformers (all-MiniLM-L6-v2)\n",
        "- Vectors capture semantic meaning\n",
        "\n",
        "**Why embeddings:**\n",
        "- Enable semantic search (\"machine learning workshop\" finds \"ML training\")\n",
        "- Similar events have similar vectors\n",
        "- Much better than keyword matching\n",
        "\n",
        "**Model details:**\n",
        "- Runs locally (no API costs)\n",
        "- ~50ms per embedding\n",
        "- First run downloads model (~80MB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize embedding service\n",
        "# First run will download the model (takes ~30 seconds)\n",
        "# Subsequent runs load from cache (~2 seconds)\n",
        "print(\"\ud83d\udd04 Loading embedding model...\")\n",
        "print(\"   (First time: downloads ~80MB model)\")\n",
        "print(\"   (Subsequent: loads from cache)\")\n",
        "\n",
        "embedder = EmbeddingService()\n",
        "\n",
        "print(f\"\\n\u2705 Embedding service initialized\")\n",
        "print(f\"   Model: {embedder.model_name}\")\n",
        "print(f\"   Dimension: {embedder.dimension}D vectors\")\n",
        "\n",
        "# Generate embeddings for each event\n",
        "if extraction_result.events:\n",
        "    print(f\"\\n\ud83d\udd22 Generating embeddings for {len(extraction_result.events)} events...\")\n",
        "    \n",
        "    event_embeddings = []\n",
        "    \n",
        "    for i, event in enumerate(extraction_result.events, 1):\n",
        "        # Combine title and description for richer embedding\n",
        "        text_to_embed = f\"{event.title} {event.description or ''}\"\n",
        "        \n",
        "        # Generate embedding\n",
        "        vector = embedder.embed_text(text_to_embed)\n",
        "        \n",
        "        event_embeddings.append({\n",
        "            'event': event,\n",
        "            'vector': vector,\n",
        "            'text': text_to_embed\n",
        "        })\n",
        "        \n",
        "        print(f\"  Event {i}: Generated {len(vector)}D vector\")\n",
        "    \n",
        "    # Show example vector (first 10 dimensions)\n",
        "    print(f\"\\n\ud83d\udcca Example Vector (first 10 dimensions):\")\n",
        "    print(f\"   {event_embeddings[0]['vector'][:10]}\")\n",
        "    print(f\"   ... (374 more dimensions)\")\n",
        "    \n",
        "    # Demonstrate semantic similarity\n",
        "    if len(event_embeddings) >= 2:\n",
        "        import numpy as np\n",
        "        \n",
        "        vec1 = np.array(event_embeddings[0]['vector'])\n",
        "        vec2 = np.array(event_embeddings[1]['vector'])\n",
        "        \n",
        "        # Cosine similarity\n",
        "        similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "        \n",
        "        print(f\"\\n\ud83d\udd0d Semantic Similarity Example:\")\n",
        "        print(f\"   Event 1: {event_embeddings[0]['event'].title}\")\n",
        "        print(f\"   Event 2: {event_embeddings[1]['event'].title}\")\n",
        "        print(f\"   Similarity: {similarity:.3f} (1.0 = identical, 0.0 = unrelated)\")\n",
        "else:\n",
        "    print(\"\\n\u26a0\ufe0f No events to embed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Store in Qdrant Vector Database\n",
        "\n",
        "**What's happening:**\n",
        "- Connect to Qdrant (running in Docker)\n",
        "- Create collection if doesn't exist\n",
        "- Store vectors + metadata (payload)\n",
        "- Build HNSW index for fast search\n",
        "\n",
        "**Qdrant concepts:**\n",
        "- **Collection**: Container for vectors (like a table)\n",
        "- **Point**: Single vector + payload\n",
        "- **Payload**: Metadata (title, date, location, etc.)\n",
        "- **HNSW**: Fast approximate nearest neighbor search\n",
        "\n",
        "**Why Qdrant:**\n",
        "- Built for vector search\n",
        "- Payload filtering (\"only upcoming events\")\n",
        "- Fast (millisecond queries)\n",
        "- Free and runs locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Qdrant client\n",
        "# This connects to Docker container at localhost:6333\n",
        "qdrant = QdrantService()\n",
        "\n",
        "print(\"\u2705 Qdrant client initialized\")\n",
        "print(f\"   Host: {qdrant.host}:{qdrant.port}\")\n",
        "print(f\"   Collection: {qdrant.collection_name}\")\n",
        "\n",
        "# Create collection (if doesn't exist)\n",
        "print(\"\\n\ud83d\uddc4\ufe0f  Creating/verifying collection...\")\n",
        "qdrant.create_collection(recreate=False)  # Don't delete existing data\n",
        "\n",
        "# Get collection info\n",
        "info = qdrant.get_collection_info()\n",
        "print(f\"\\n\ud83d\udcca Collection Info:\")\n",
        "print(f\"   Name: {info['name']}\")\n",
        "print(f\"   Points: {info['points_count']}\")\n",
        "print(f\"   Status: {info['status']}\")\n",
        "\n",
        "# Prepare points for insertion\n",
        "if event_embeddings:\n",
        "    from qdrant_client.models import PointStruct\n",
        "    \n",
        "    print(f\"\\n\ud83d\udcbe Preparing {len(event_embeddings)} points for storage...\")\n",
        "    \n",
        "    points = []\n",
        "    \n",
        "    for item in event_embeddings:\n",
        "        event = item['event']\n",
        "        vector = item['vector']\n",
        "        \n",
        "        # Create point with unique ID\n",
        "        point = PointStruct(\n",
        "            id=str(uuid.uuid4()),  # Unique identifier\n",
        "            vector=vector,  # 384D embedding\n",
        "            payload={  # Metadata for filtering and display\n",
        "                'title': event.title,\n",
        "                'description': event.description,\n",
        "                'start_time': event.start_time,\n",
        "                'end_time': event.end_time,\n",
        "                'timezone': event.timezone,\n",
        "                'location': event.location,\n",
        "                'registration_link': str(event.registration_link) if event.registration_link else None,\n",
        "                'tags': event.tags,\n",
        "                'organizer': event.organizer,\n",
        "                'cost': event.cost,\n",
        "                'status': event.compute_status().value,\n",
        "                'source_email_id': emails[0]['id'],\n",
        "                'source_subject': emails[0]['subject'],\n",
        "                'source_from': emails[0]['from'],\n",
        "                'type': 'event',\n",
        "                'extracted_at': datetime.now().isoformat()\n",
        "            }\n",
        "        )\n",
        "        \n",
        "        points.append(point)\n",
        "        print(f\"  \u2713 Prepared: {event.title}\")\n",
        "    \n",
        "    # Insert into Qdrant\n",
        "    print(f\"\\n\ud83d\udce4 Upserting points to Qdrant...\")\n",
        "    qdrant.upsert_points(points)\n",
        "    \n",
        "    print(f\"\\n\u2705 Successfully stored {len(points)} events!\")\n",
        "    \n",
        "    # Get updated collection info\n",
        "    updated_info = qdrant.get_collection_info()\n",
        "    print(f\"\\n\ud83d\udcca Updated Collection:\")\n",
        "    print(f\"   Total points: {updated_info['points_count']}\")\n",
        "else:\n",
        "    print(\"\\n\u26a0\ufe0f No events to store\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Semantic Search\n",
        "\n",
        "**What's happening:**\n",
        "- Convert search query to vector\n",
        "- Find similar vectors in Qdrant\n",
        "- Return events ranked by similarity\n",
        "- Apply filters (type, status, etc.)\n",
        "\n",
        "**How it works:**\n",
        "1. Query: \"machine learning workshop\" \u2192 vector\n",
        "2. Qdrant finds nearest neighbor vectors\n",
        "3. Returns events with similarity scores\n",
        "4. Higher score = more relevant\n",
        "\n",
        "**Magic of semantic search:**\n",
        "- \"ML training\" matches \"machine learning workshop\"\n",
        "- \"AI conference\" matches \"artificial intelligence summit\"\n",
        "- Works across synonyms and related concepts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's try some searches!\n",
        "print(\"\ud83d\udd0d Semantic Search Demo\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Define search queries\n",
        "search_queries = [\n",
        "    \"machine learning workshop\",\n",
        "    \"AI conference\",\n",
        "    \"data science event\",\n",
        "    \"online webinar\"\n",
        "]\n",
        "\n",
        "for query in search_queries:\n",
        "    print(f\"\\n\ud83d\udd0e Query: '{query}'\")\n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    # Generate query vector\n",
        "    query_vector = embedder.embed_text(query)\n",
        "    \n",
        "    # Search Qdrant\n",
        "    # Parameters:\n",
        "    #   query_vector: The embedding of our search query\n",
        "    #   limit: How many results to return\n",
        "    #   filter_dict: Optional filters (e.g., only upcoming events)\n",
        "    results = qdrant.search(\n",
        "        query_vector=query_vector,\n",
        "        limit=3,\n",
        "        filter_dict={'type': 'event'}  # Only return events\n",
        "    )\n",
        "    \n",
        "    if results:\n",
        "        print(f\"Found {len(results)} results:\\n\")\n",
        "        \n",
        "        for i, result in enumerate(results, 1):\n",
        "            payload = result['payload']\n",
        "            score = result['score']\n",
        "            \n",
        "            print(f\"{i}. {payload['title']}\")\n",
        "            print(f\"   \ud83d\udcca Relevance: {score:.3f} (0.0 - 1.0)\")\n",
        "            print(f\"   \ud83d\udccd Location: {payload.get('location', 'N/A')}\")\n",
        "            print(f\"   \ud83d\udcc5 Start: {payload.get('start_time', 'N/A')}\")\n",
        "            print(f\"   \u23f0 Status: {payload.get('status', 'N/A')}\")\n",
        "            print(f\"   \ud83d\udd17 Link: {payload.get('registration_link', 'N/A')[:60]}...\")\n",
        "            print()\n",
        "    else:\n",
        "        print(\"No results found\\n\")\n",
        "\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Advanced Search with Filters\n",
        "\n",
        "**Payload filtering:**\n",
        "- Search within specific criteria\n",
        "- Combine semantic search + filters\n",
        "- Much more powerful than search alone\n",
        "\n",
        "**Examples:**\n",
        "- \"ML events\" + only upcoming\n",
        "- \"conferences\" + only free\n",
        "- \"workshops\" + only online"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\ud83c\udfaf Filtered Search Demo\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Search 1: Only upcoming events\n",
        "print(\"\\n\ud83d\udd0e Search: 'AI event' (upcoming only)\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "query_vec = embedder.embed_text(\"AI event\")\n",
        "results = qdrant.search(\n",
        "    query_vector=query_vec,\n",
        "    limit=5,\n",
        "    filter_dict={\n",
        "        'type': 'event',\n",
        "        'status': 'upcoming'  # Only future events\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"Found {len(results)} upcoming events\\n\")\n",
        "for i, r in enumerate(results, 1):\n",
        "    print(f\"{i}. {r['payload']['title']} (score: {r['score']:.3f})\")\n",
        "\n",
        "# Search 2: Only online events\n",
        "print(\"\\n\ud83d\udd0e Search: 'workshop' (online only)\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "query_vec = embedder.embed_text(\"workshop\")\n",
        "results = qdrant.search(\n",
        "    query_vector=query_vec,\n",
        "    limit=5,\n",
        "    filter_dict={\n",
        "        'type': 'event',\n",
        "        'location': 'Online'  # Only virtual events\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"Found {len(results)} online workshops\\n\")\n",
        "for i, r in enumerate(results, 1):\n",
        "    print(f\"{i}. {r['payload']['title']} (score: {r['score']:.3f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary: Complete Pipeline\n",
        "\n",
        "**What we accomplished:**\n",
        "\n",
        "1. \u2705 **Fetched emails** from Gmail API\n",
        "2. \u2705 **Parsed HTML** to clean text\n",
        "3. \u2705 **Extracted events** using LLM structured output\n",
        "4. \u2705 **Generated embeddings** for semantic search\n",
        "5. \u2705 **Stored in Qdrant** with rich metadata\n",
        "6. \u2705 **Searched semantically** with filters\n",
        "\n",
        "**Key learnings:**\n",
        "\n",
        "- **Gmail API**: OAuth authentication, multipart emails\n",
        "- **HTML Parsing**: BeautifulSoup4, tracking pixel removal\n",
        "- **LLM Extraction**: Structured output guarantees valid JSON\n",
        "- **Embeddings**: 384D vectors capture semantic meaning\n",
        "- **Qdrant**: Vector database with payload filtering\n",
        "- **Semantic Search**: Find by meaning, not just keywords\n",
        "\n",
        "**Performance:**\n",
        "\n",
        "- Email fetch: ~3s for 5 emails\n",
        "- HTML parsing: ~50ms per email\n",
        "- Event extraction: ~2-3s per email\n",
        "- Embedding: ~50ms per event\n",
        "- Qdrant storage: ~200ms for batch\n",
        "- Search: ~100ms per query\n",
        "\n",
        "**Next steps:**\n",
        "\n",
        "- **Phase 2**: Add courses and blogs extraction\n",
        "- **Phase 3**: Implement hybrid search (dense + sparse)\n",
        "- **Phase 4**: Advanced Qdrant features (grouping, discovery)\n",
        "- **Phase 5**: Deduplication and temporal reasoning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bonus: Process Multiple Emails\n",
        "\n",
        "Now that you understand each step, let's process all fetched emails in a loop!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\ud83d\udd04 Processing All Emails\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "total_events = 0\n",
        "all_points = []\n",
        "\n",
        "for i, email in enumerate(emails, 1):\n",
        "    print(f\"\\n[{i}/{len(emails)}] Processing: {email['subject'][:60]}...\")\n",
        "    \n",
        "    try:\n",
        "        # Skip if no HTML\n",
        "        if not email['body_html']:\n",
        "            print(\"  \u26a0\ufe0f No HTML body, skipping\")\n",
        "            continue\n",
        "        \n",
        "        # Parse\n",
        "        parsed = parser.parse_html_email(email['body_html'])\n",
        "        print(f\"  \u2713 Parsed: {len(parsed['text'])} chars, {len(parsed['links'])} links\")\n",
        "        \n",
        "        # Extract\n",
        "        result = await extractor.extract_events(parsed['text'], email['subject'])\n",
        "        print(f\"  \u2713 Extracted: {len(result.events)} events (confidence: {result.confidence:.2f})\")\n",
        "        \n",
        "        if not result.events:\n",
        "            continue\n",
        "        \n",
        "        # Embed and create points\n",
        "        for event in result.events:\n",
        "            text = f\"{event.title} {event.description or ''}\"\n",
        "            vector = embedder.embed_text(text)\n",
        "            \n",
        "            from qdrant_client.models import PointStruct\n",
        "            point = PointStruct(\n",
        "                id=str(uuid.uuid4()),\n",
        "                vector=vector,\n",
        "                payload={\n",
        "                    'title': event.title,\n",
        "                    'description': event.description,\n",
        "                    'start_time': event.start_time,\n",
        "                    'location': event.location,\n",
        "                    'registration_link': str(event.registration_link) if event.registration_link else None,\n",
        "                    'tags': event.tags,\n",
        "                    'status': event.compute_status().value,\n",
        "                    'source_email_id': email['id'],\n",
        "                    'source_subject': email['subject'],\n",
        "                    'type': 'event'\n",
        "                }\n",
        "            )\n",
        "            all_points.append(point)\n",
        "        \n",
        "        total_events += len(result.events)\n",
        "        print(f\"  \u2713 Created {len(result.events)} points\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  \u274c Error: {e}\")\n",
        "        continue\n",
        "\n",
        "# Store all points\n",
        "if all_points:\n",
        "    print(f\"\\n\ud83d\udcbe Storing {len(all_points)} total events...\")\n",
        "    qdrant.upsert_points(all_points)\n",
        "    print(f\"\u2705 Complete!\")\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 70)\n",
        "print(f\"\ud83d\udcca Final Statistics:\")\n",
        "print(f\"   Emails processed: {len(emails)}\")\n",
        "print(f\"   Events extracted: {total_events}\")\n",
        "print(f\"   Points stored: {len(all_points)}\")\n",
        "\n",
        "# Final collection info\n",
        "final_info = qdrant.get_collection_info()\n",
        "print(f\"   Total in database: {final_info['points_count']} points\")\n",
        "print(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}