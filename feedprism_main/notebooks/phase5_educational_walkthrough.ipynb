{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53ad0f9f",
   "metadata": {},
   "source": [
    "\n",
    "# Phase 5: Advanced Features Walkthrough\n",
    "\n",
    "In this notebook, we explore the advanced features implemented in Phase 5 of FeedPrism:\n",
    "\n",
    "1.  **Discovery API (Recommendations)**: Finding similar content using Qdrant's `discover` API.\n",
    "2.  **Scroll API (Analytics)**: Efficiently iterating through large datasets to generate analytics.\n",
    "3.  **HNSW Benchmarking**: Evaluating vector search performance with different index configurations.\n",
    "\n",
    "These features demonstrate the production-readiness of the system, moving beyond basic search to provide insights and personalized recommendations.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1c2fa5",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Setup and Initialization\n",
    "\n",
    "First, we set up the environment and initialize our services.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c884e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Shared/ALL WORKSPACE/Hackathons/mom_hack/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Services imported successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import asyncio\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent.absolute()\n",
    "os.chdir(project_root)\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from app.services.recommender import RecommendationService\n",
    "from app.services.analytics import AnalyticsService\n",
    "from app.database.qdrant_client import QdrantService\n",
    "from app.services.embedder import EmbeddingService\n",
    "\n",
    "print(\"‚úÖ Services imported successfully\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a98b0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-27 18:45:58.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.database.qdrant_client\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mConnecting to Qdrant: localhost:6333\u001b[0m\n",
      "\u001b[32m2025-11-27 18:45:58.664\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mapp.database.qdrant_client\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[32m\u001b[1mQdrant client initialized\u001b[0m\n",
      "\u001b[32m2025-11-27 18:45:58.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.database.qdrant_client\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mConnecting to Qdrant: localhost:6333\u001b[0m\n",
      "\u001b[32m2025-11-27 18:45:58.672\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mapp.database.qdrant_client\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[32m\u001b[1mQdrant client initialized\u001b[0m\n",
      "\u001b[32m2025-11-27 18:45:58.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.database.qdrant_client\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mConnecting to Qdrant: localhost:6333\u001b[0m\n",
      "\u001b[32m2025-11-27 18:45:58.679\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mapp.database.qdrant_client\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[32m\u001b[1mQdrant client initialized\u001b[0m\n",
      "\u001b[32m2025-11-27 18:45:58.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.services.embedder\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mLoading embedding model: sentence-transformers/all-MiniLM-L6-v2\u001b[0m\n",
      "\u001b[32m2025-11-27 18:46:02.497\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mapp.services.embedder\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m29\u001b[0m - \u001b[32m\u001b[1mModel loaded: 384D vectors\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Services initialized\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize services\n",
    "recommender = RecommendationService()\n",
    "analytics = AnalyticsService()\n",
    "qdrant = QdrantService()\n",
    "embedder = EmbeddingService()\n",
    "\n",
    "print(\"‚úÖ Services initialized\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0164bca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebd8acc6",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Discovery API (Recommendations)\n",
    "\n",
    "The **Discovery API** in Qdrant is designed for \"recommendation\" use cases. Unlike standard search (which finds nearest neighbors to a query vector), Discovery can use a *target* point (context) to find similar items, potentially constrained by positive and negative examples (though we use the simpler target-based approach here).\n",
    "\n",
    "We implemented `RecommendationService.discover_similar` to wrap this functionality.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f45e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-27 18:46:08.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.database.qdrant_client\u001b[0m:\u001b[36msearch\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1mSearching feedprism_events using title (limit=1)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found target event: Unique Event (ID: c0967154-a692-4c3a-90cf-ce6dc0dd84b1)\n",
      "\n",
      "üîç Discovering similar events...\n",
      "1. Duplicate Event (Score: 0.722)\n",
      "2. Duplicate Event (Score: 0.718)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's first find an event to use as our \"target\"\n",
    "# We'll search for something generic to get a valid ID\n",
    "results = qdrant.search(\n",
    "    query_vector=embedder.embed_text(\"AI conference\"),\n",
    "    content_type=\"events\",\n",
    "    limit=1\n",
    ")\n",
    "\n",
    "if results:\n",
    "    target_event = results[0]\n",
    "    target_id = target_event['id']\n",
    "    print(f\"Found target event: {target_event['payload'].get('title')} (ID: {target_id})\")\n",
    "    \n",
    "    # Now, let's ask for recommendations similar to this event\n",
    "    print(f\"\\nüîç Discovering similar events...\")\n",
    "    recommendations = recommender.discover_similar(\n",
    "        item_id=target_id,\n",
    "        content_type=\"events\",\n",
    "        limit=3\n",
    "    )\n",
    "    \n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"{i}. {rec['payload'].get('title')} (Score: {rec['score']:.3f})\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No events found to test recommendations. Run ingestion first.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9bffda",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Scroll API (Analytics)\n",
    "\n",
    "The **Scroll API** allows us to iterate through all points in a collection, which is essential for analytics where we need to aggregate data across the entire dataset (or a large filtered subset) rather than just finding the top-k matches.\n",
    "\n",
    "We implemented `AnalyticsService.get_email_stats` to calculate:\n",
    "- Total items processed\n",
    "- Breakdown by content type\n",
    "- Top organizers, providers, and tags\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e5e4b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Generating analytics...\n",
      "Total Items: 4\n",
      "Avg per week: 0.9\n",
      "\n",
      "By Type:\n",
      "{'blogs': 1, 'events': 3}\n",
      "\n",
      "Top Tags:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get analytics for the last 30 days\n",
    "print(\"üìä Generating analytics...\")\n",
    "stats = analytics.get_email_stats(days=30)\n",
    "\n",
    "print(f\"Total Items: {stats['total_items']}\")\n",
    "print(f\"Avg per week: {stats['avg_per_week']:.1f}\")\n",
    "print(\"\\nBy Type:\")\n",
    "pprint(stats['by_type'])\n",
    "\n",
    "print(\"\\nTop Tags:\")\n",
    "pprint(stats['top_tags'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe4708c",
   "metadata": {},
   "source": [
    "\n",
    "## 4. HNSW Benchmarking\n",
    "\n",
    "To ensure production readiness, we benchmarked different HNSW (Hierarchical Navigable Small World) index configurations. HNSW is the algorithm Qdrant uses for approximate nearest neighbor search.\n",
    "\n",
    "Key parameters:\n",
    "- **m**: Number of connections per node. Higher `m` = better recall but higher memory/build time.\n",
    "- **ef_construct**: Size of the dynamic list during index construction. Higher = better index quality but slower build.\n",
    "\n",
    "We ran `scripts/benchmark_hnsw.py` to test three configurations:\n",
    "1.  **High Precision**: m=32, ef=400\n",
    "2.  **Balanced**: m=16, ef=200\n",
    "3.  **Fast**: m=8, ef=100\n",
    "\n",
    "Here are the results:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a3cea43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# HNSW Benchmark Results\n",
       "\n",
       "| Configuration | Precision@10 | Latency (p95) | Memory |\n",
       "|---------------|--------------|---------------|--------|\n",
       "| High Precision | 0.950 | 4.9ms | 1.46MB |\n",
       "| Balanced | 0.950 | 1.6ms | 1.46MB |\n",
       "| Fast | 0.950 | 1.8ms | 1.46MB |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Read and display the benchmark results\n",
    "benchmark_file = os.path.join(project_root, \"docs\", \"benchmarks.md\")\n",
    "\n",
    "if os.path.exists(benchmark_file):\n",
    "    from IPython.display import Markdown\n",
    "    with open(benchmark_file, \"r\") as f:\n",
    "        content = f.read()\n",
    "    display(Markdown(content))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Benchmark results not found. Run `python scripts/benchmark_hnsw.py` first.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6192a96f",
   "metadata": {},
   "source": [
    "\n",
    "### Evaluation\n",
    "\n",
    "Based on the benchmarks, we can observe the trade-offs. For FeedPrism, we typically choose a **Balanced** configuration (default in Qdrant) as it offers a good mix of speed and accuracy without excessive memory usage. The \"High Precision\" mode might be necessary if the corpus grows significantly (millions of vectors), while \"Fast\" is suitable for very resource-constrained environments.\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
