# FeedPrism Demo Video Script
## Memory Over Models â€” AI Hackathon Submission

**Target Duration:** 5-6 minutes  
**Format:** Screen recording with voiceover  
**Theme:** Unstructured Data RAG Challenge  
**Primary Sponsor:** Qdrant  
**Secondary Sponsor:** Lamatic (optional integration)

---

# ğŸ¬ COMPLETE DEMO WALKTHROUGH WITH NARRATION

This script includes **every click, every screen, and every word** you'll speak. Follow it step by step.

---

## SCENE 1: DOCKER COMPOSE SETUP (0:00 - 0:30)

### Screen Actions:
1. Open Terminal
2. Navigate to the project root directory
3. Show the `docker-compose.yml` file briefly (optional)
4. Run `docker compose up`
5. Wait for all 4 services to start

### What You Type:
```bash
# Single command to start everything
docker compose up -d

# Or with build (first time)
docker compose up --build -d
```

### What You See in Terminal:
```
[+] Running 4/4
 âœ” Container feedprism-qdrant         Started
 âœ” Container feedprism-backend        Started
 âœ” Container feedprism-frontend       Started
 âœ” Container feedprism-lamatic-bridge Started
```

### Narration:
> "Welcome to FeedPrism â€” an intelligent email intelligence system built for the Memory Over Models hackathon.
> 
> FeedPrism runs as a complete Docker stack with four services. Let me start everything with a single command: `docker compose up`.
> 
> [Wait for containers to start]
> 
> Here we go â€” four containers spinning up:
> - **Qdrant** â€” our vector database with API key authentication
> - **Backend** â€” FastAPI server handling extraction and search
> - **Frontend** â€” React app served via Nginx on port 80
> - **Lamatic Bridge** â€” webhook receiver for Lamatic AI integration
> 
> All services are connected. Qdrant is the memory backbone. Let's open the app."

---

### Architecture Note (mention verbally):
> "This is production-ready architecture. Qdrant runs with persistent storage and API key authentication. The backend connects securely using the same API key. Everything is containerized and reproducible."

---

## SCENE 2: OPENING THE APP â€” DEMO MODE BANNER (0:30 - 0:50)

### Screen Actions:
1. Open browser to `http://localhost` (port 80 via Nginx)
2. Point out the **"Demo Mode"** banner at the top
3. Show the sidebar with navigation items
4. Point to the "Home" view being active

### What You See:
- Yellow/orange "Demo Mode" banner at top saying "You're viewing FeedPrism in demo mode with sample data"
- Sidebar with: Home, Events, Courses, Blogs, Metrics, Settings
- Main content area with Prism Overview section

### Narration:
> "Here's FeedPrism running in demo mode at localhost port 80. The frontend is served via Nginx for production-like performance.
> 
> You'll see this banner at the top indicating we're using pre-loaded sample data. We've implemented full Gmail OAuth integration, but for this hackathon demo, we're using curated newsletters to simplify the judging experience.
> 
> On the left, you see our sidebar â€” Home, Events, Courses, Blogs, Metrics, and Settings. Each represents a different view of the same Qdrant-backed data.
> 
> Let me show you how FeedPrism transforms messy emails into organized knowledge."

---

## SCENE 3: PRISM OVERVIEW â€” THE PROBLEM (0:50 - 1:20)

### Screen Actions:
1. Scroll to the **Prism Overview** section
2. Point to the **left panel** showing unprocessed emails
3. Hover over individual email cards to show details
4. Read out some email subjects

### What You See:
- Left panel: "Unprocessed Emails" with 6 demo emails:
  - "Last Week in AI #226 - Gemini 3, Claude 4, and AI Agents" (from Last Week in AI)
  - "Coursera Weekly: New Machine Learning Courses" (from Coursera)
  - "Tech Events This Week - AI Summit, React Conf, DevOps Days" (from Eventbrite Digest)
  - "The Pragmatic Engineer: How Big Tech Does Code Reviews" (from Gergely Orosz)
  - "Python Weekly: FastAPI 0.110, Django 5.0, and Async Patterns" (from Python Weekly)
  - "Hacker Newsletter: Top Stories from Hacker News" (from Hacker Newsletter)
- Center: Prism visual/image
- Right panel: "Extract Content" button

### Narration:
> "This is the core problem FeedPrism solves. Look at these six unprocessed emails on the left â€” newsletters from Last Week in AI, Coursera, Eventbrite, The Pragmatic Engineer, Python Weekly, and Hacker Newsletter.
> 
> Each of these emails contains MULTIPLE pieces of valuable content buried in HTML â€” events with dates and locations, courses with instructors and pricing, blog articles with key insights.
> 
> A typical professional receives 50 to 200 of these content-rich emails monthly. Valuable information gets buried. Events get missed. Course deadlines pass unnoticed.
> 
> The name FeedPrism comes from this exact concept â€” just like a prism refracts white light into a spectrum of colors, FeedPrism takes a messy feed of raw emails and refracts them into organized categories: Events, Courses, and Blogs."

---

## SCENE 4: EXTRACTION IN ACTION (1:20 - 2:00)

### Screen Actions:
1. Click the **"Extract Content"** button
2. Watch the **real-time progress** appear:
   - "Fetching email 1/6..."
   - "Parsing: Last Week in AI #226..."
   - "Extracting content with LLM..."
   - "Generating embeddings..."
   - "Ingesting to Qdrant..."
3. Watch the progress indicators update
4. Wait for extraction to complete
5. See the **results summary** appear

### What You See:
- Progress bar moving
- Step-by-step messages streaming via SSE
- Counter showing: Events: 5, Courses: 4, Blogs: 6 (or similar)
- "Extraction Complete" message

### Narration:
> "Now watch the extraction in real-time. I'll click Extract Content.
> 
> [Click button]
> 
> See those progress messages? That's Server-Sent Events streaming from our FastAPI backend directly to the browser. No polling â€” real-time updates.
> 
> Here's what's happening under the hood:
> 
> First, we fetch each email. Then we parse the HTML content to extract clean text. Next, Google Gemini analyzes the content and extracts structured items â€” events with dates, courses with instructors, articles with key points.
> 
> For each extracted item, we generate THREE embedding vectors using sentence-transformers â€” one for the title, one for the description, and one for the full text. This multi-representation approach is key to high-quality search.
> 
> We also generate a SPARSE vector using BM25-style term frequency hashing for keyword matching.
> 
> Finally, each item is upserted to Qdrant with all its metadata as payload â€” source email ID, sender, tags, dates, everything.
> 
> [Wait for completion]
> 
> Done! We've extracted 5 events, 4 courses, and 6 blog articles from just 6 newsletters. Let's see what we got."

---

## SCENE 5: THE MAIN FEED â€” QDRANT MULTI-COLLECTION (2:00 - 2:40)

### Screen Actions:
1. Scroll down to the **Feed** section below the Prism Overview
2. Show the **extracted item cards** appearing
3. Point out the **type badges** (Event, Course, Blog) on cards
4. Hover over cards to show details

### What You See:
- Feed showing mixed content: Events (calendar icon, purple), Courses (book icon, green), Blogs (article icon, blue)
- Each card shows: Title, sender, tags, date/time, action buttons
- Cards have "View Source" buttons

### Narration:
> "Here's our intelligent feed. Every card you see represents content extracted from those newsletters and stored in Qdrant.
> 
> Notice the color coding â€” purple for Events, green for Courses, blue for Blogs. Each type has its OWN Qdrant collection with CUSTOM HNSW parameters.
> 
> Let me explain what that means technically:
> 
> Events use m=16 and ef_construct=200. The 'm' parameter controls how many connections each node has in the HNSW graph â€” higher means better recall. ef_construct=200 means we build a high-quality index. For events, we want HIGH RECALL â€” you never want to miss an upcoming conference.
> 
> Courses use m=24 and ef_construct=100 â€” more connections for balanced precision and recall, but faster index building since course catalogs update less frequently.
> 
> Blogs use m=16 and ef_construct=150 â€” optimized for FAST retrieval since users browse articles quickly.
> 
> This isn't one-size-fits-all. We deliberately tuned each collection for its specific use case. That's the kind of Qdrant depth judges should look for."

---

## SCENE 6: FILTER BAR â€” PAYLOAD FILTERING (2:40 - 3:15)

### Screen Actions:
1. Click on the **Filter Bar** area
2. Click **"Events"** filter chip to filter by type
3. Show only Event cards appearing
4. Click **"Courses"** to switch
5. Show Course cards appearing
6. Click **"Blogs"** to switch
7. Clear filters by clicking "All"
8. Click on a **Sender filter** dropdown
9. Select one sender (e.g., "Coursera")
10. Show filtered results
11. Click on a **Tag** to filter by tag

### What You See:
- Filter chips: Events, Courses, Blogs, Upcoming, Past
- Sender dropdown with checkboxes
- Tag chips below filters
- Feed updating instantly on each filter click

### Narration:
> "Now let me show you Qdrant's payload filtering in action.
> 
> [Click Events]
> 
> I click 'Events' â€” instantly, only events appear. This isn't client-side JavaScript filtering. This is Qdrant's payload filtering happening BEFORE vector search.
> 
> [Click Courses]
> 
> Courses. [Click Blogs] Blogs.
> 
> Every item in Qdrant stores rich metadata as payload: source_email_id, sender_email, tags, start_time, location, provider â€” all queryable fields.
> 
> [Click Sender dropdown, select one]
> 
> I can filter by sender. Let me select Coursera. Now I only see content from Coursera's newsletters.
> 
> [Click a tag]
> 
> Or filter by tag. Let me click 'AI'. Now I see all AI-related content across events, courses, and blogs.
> 
> This is the power of Qdrant's payload filtering. The filter conditions narrow down the candidate set FIRST, then vector search only runs on matching documents. It's efficient and precise."

---

## SCENE 7: SEMANTIC SEARCH â€” HYBRID SEARCH WITH RRF (3:15 - 4:00)

### Screen Actions:
1. Click on the **Search Bar** (or press Cmd+K to open command palette)
2. Type: **"machine learning"**
3. Wait for results to appear
4. Point out results that match semantically (not just keyword)
5. Clear and search: **"Python tutorials"**
6. Show results
7. Clear and search: **"upcoming conferences"**
8. Show event results with dates

### What You See:
- Search bar with placeholder text
- Results appearing as you type (debounced)
- Results showing items that don't contain exact keywords but are semantically related

### Narration:
> "Let me demonstrate our hybrid search system. I'll press Cmd+K to open the command palette, or I can use the search bar directly.
> 
> [Type 'machine learning']
> 
> I search for 'machine learning'. Look at these results â€” we find the MLOps course, the TensorFlow course, articles about AI â€” even though some don't contain the exact phrase 'machine learning'.
> 
> This is hybrid search in action. We combine:
> - DENSE vectors from sentence-transformers for semantic similarity â€” 'machine learning' matches 'deep learning' and 'neural networks'
> - SPARSE vectors using BM25-style term frequency â€” exact keyword matches like 'ML' or 'TensorFlow'
> 
> The results are fused using Reciprocal Rank Fusion with k=60. The formula is 1/(k + rank) â€” this gives appropriate weight to both ranking systems.
> 
> [Search 'Python tutorials']
> 
> Let me try 'Python tutorials'. We find Python Weekly content, FastAPI articles, and programming courses â€” all semantically related.
> 
> [Search 'upcoming conferences']
> 
> Or 'upcoming conferences'. Now we see events â€” AI Summit, React Conf, DevOps Days â€” with their dates. The payload filtering and vector search work together.
> 
> Dense-only search would miss keyword matches. Sparse-only would miss semantic relationships. Hybrid gets both."

---

## SCENE 8: SOURCE TRACEABILITY â€” ZERO HALLUCINATION (4:00 - 4:30)

### Screen Actions:
1. Find any **extracted item card** in the feed
2. Click the **"Source"** or **"View Original Email"** button
3. Show the **Email Modal** appearing
4. Point out the original email content
5. Scroll through the email to show where the item was extracted from
6. Close the modal

### What You See:
- Email Modal overlay
- Original email with full HTML content
- Header showing sender, subject, received date
- Body showing the newsletter content

### Narration:
> "This is my favorite feature and critical for AI trustworthiness â€” source traceability.
> 
> Every extracted item stores its source_email_id in the Qdrant payload. Watch what happens when I click 'View Source' on this event card.
> 
> [Click Source button]
> 
> Here's the original email this event was extracted from. You can see the full newsletter â€” the same AI Summit event is right here in the HTML.
> 
> This is PROVENANCE â€” the foundation of trustworthy AI. No hallucination. No fabricated content. Every piece of extracted information can be traced back to its source.
> 
> Judges can verify any item. Click Source, see the email, confirm the extraction is accurate. This is what 'Memory Over Models' means in practice â€” we're not generating content, we're remembering and organizing what's already there.
> 
> [Close modal]
> 
> Zero hallucination, full traceability."

---

## SCENE 9: EVENTS CALENDAR VIEW (4:30 - 4:55)

### Screen Actions:
1. Click **"Events"** in the sidebar
2. Show the **Calendar View** loading
3. Point to events displayed on calendar dates
4. Click on a date with events
5. Show event details appearing
6. Click on an event to see full details
7. Point out the "Add to Calendar" button

### What You See:
- Calendar grid (month view)
- Colored dots/blocks on dates with events
- Event cards when clicking a date
- Event details: title, date, time, location, price, registration link

### Narration:
> "Different content types deserve different views. Let me click 'Events' in the sidebar.
> 
> [Click Events]
> 
> This is our calendar view. Every event we extracted has a start_time stored in its Qdrant payload. We query Qdrant filtering by item_type='event', retrieve the start_time payloads, and render them on this calendar.
> 
> [Click on a date]
> 
> See these dots? Each represents an event. Let me click on January 15th â€” here's AI Summit 2025 in San Francisco, $599 early bird pricing, with a registration link.
> 
> [Point to Add to Calendar]
> 
> Users can add events directly to their calendar. All this metadata â€” dates, locations, prices â€” comes from the Qdrant payload. The vector embedding helps us FIND relevant events; the payload gives us the DETAILS to display."

---

## SCENE 10: BLOGS GALLERY VIEW (4:55 - 5:15)

### Screen Actions:
1. Click **"Blogs"** in the sidebar
2. Show the **Gallery View** loading
3. Point to the grid/list layout
4. Toggle between grid and list views if available
5. Hover over blog cards to show details
6. Point out tags, reading time, source

### What You See:
- Grid of blog article cards
- Each card: title, image (if available), snippet, tags, reading time
- Source attribution (Pragmatic Engineer, Hacker Newsletter, etc.)

### Narration:
> "Now Blogs. [Click Blogs]
> 
> Here's our gallery view for articles and blog posts. Each card shows the title, a preview snippet, tags, estimated reading time, and the source newsletter.
> 
> [Hover over cards]
> 
> 'How Big Tech Does Code Reviews' from Gergely Orosz. 'Why SQLite is Taking Over' from Hacker Newsletter. 'Inside Gemini 3's Architecture' from Last Week in AI.
> 
> All this content was buried in those six newsletters. Now it's organized, searchable, and filterable â€” all backed by Qdrant."

---

## SCENE 11: COURSES CATALOG VIEW (5:15 - 5:35)

### Screen Actions:
1. Click **"Courses"** in the sidebar
2. Show the **Catalog View** loading
3. Point to provider badges (Coursera, Udemy, etc.)
4. Point to level indicators (Beginner, Intermediate)
5. Point to pricing (Free, $49, etc.)
6. Point to instructor names
7. Click on a course to see details

### What You See:
- Course cards with provider branding
- Level badges: Beginner (green), Intermediate (yellow), Advanced (red)
- Duration: "6 weeks", "4 weeks"
- Pricing: "Free", "$49", "$19.99"
- Instructor names

### Narration:
> "And Courses. [Click Courses]
> 
> Our catalog view shows courses with rich metadata. Provider badges â€” Coursera, Udemy. Level indicators â€” Beginner, Intermediate. Duration â€” 3 weeks, 6 weeks. Pricing â€” Free or paid.
> 
> [Point to details]
> 
> 'Advanced TensorFlow for Production' by Laurence Moroney, 6 weeks, Intermediate, Free on Coursera. 'Generative AI with LangChain' by Harrison Chase, 3 weeks, Beginner, Free.
> 
> All extracted from newsletter emails, all stored with full metadata in Qdrant payloads. The UI adapts to content type, but the data is unified in our vector database."

---

## SCENE 12: METRICS DASHBOARD (5:35 - 5:55)

### Screen Actions:
1. Click **"Metrics"** in the sidebar
2. Show the **Metrics Dashboard**
3. Point to total items extracted
4. Point to category breakdown
5. Point to top tags
6. Point to any quality metrics shown

### What You See:
- Total emails processed: X
- Total items extracted: Y
- Categories: Events (N), Courses (N), Blogs (N)
- Top tags: AI, Python, Machine Learning, etc.
- Possibly: Precision, MRR, Latency metrics

### Narration:
> "Finally, our Metrics dashboard. [Click Metrics]
> 
> This is powered by Qdrant's Scroll API â€” efficiently iterating through collections to compute analytics.
> 
> We've processed X emails and extracted Y items. Category breakdown: N events, N courses, N blogs. Top tags across all content: AI, Python, Machine Learning, DevOps.
> 
> For the hackathon, we also track quality metrics â€” precision around 82%, mean reciprocal rank around 0.65, p95 latency under 800ms. These metrics demonstrate our system produces high-quality, relevant results.
> 
> This isn't just a demo â€” it's a production-ready system with measurable quality."

---

## SCENE 13: LAMATIC BRIDGE INTEGRATION (5:55 - 6:15)

### Screen Actions:
1. Open a new terminal tab
2. Show the Lamatic Bridge container logs (optional)
3. Explain the webhook architecture

### What You Type (optional):
```bash
# View Lamatic Bridge logs
docker logs feedprism-lamatic-bridge
```

### Narration:
> "FeedPrism also integrates with Lamatic AI â€” the hackathon's secondary sponsor.
> 
> We've built a dedicated Lamatic Bridge service running on port 8001. When Lamatic sends a webhook with new email data, the bridge receives it and forwards it to FeedPrism for processing.
> 
> The bridge handles the communication layer while FeedPrism handles idempotency â€” if an email has already been processed, we check Qdrant using the source_email_id payload and skip duplicate processing.
> 
> This architecture enables real-time email processing triggered by external workflow automation tools like Lamatic."

---

## SCENE 14: CLOSING â€” MEMORY OVER MODELS (6:15 - 6:45)

### Screen Actions:
1. Return to **Home** view
2. Show the full app one more time
3. Scroll through the feed slowly

### Narration:
> "Let me bring it all together.
> 
> [Return to Home]
> 
> FeedPrism transforms email chaos into organized, searchable knowledge. But the key insight is this: we're not using AI to GENERATE content â€” we're using AI to REMEMBER and RETRIEVE it.
> 
> The Qdrant vector database IS the product. Every extracted event, course, and blog becomes persistent memory:
> - Multi-collection architecture with tuned HNSW parameters
> - Named vectors for multi-representation search
> - Hybrid dense-plus-sparse search with RRF fusion
> - Rich payload filtering that happens BEFORE vector search
> - Scroll API for analytics
> - Discovery API for recommendations
> - Source traceability for every single item
> - API key authentication for secure access
> - Lamatic Bridge for external workflow integration
> 
> All running in Docker with a single `docker compose up` command.
> 
> This is what 'Memory Over Models' means in practice. The best AI isn't about generating new content â€” it's about perfectly remembering and retrieving what already exists.
> 
> FeedPrism. Powered by Qdrant. Integrated with Lamatic. Built for the Memory Over Models hackathon.
> 
> Thank you for watching."

---

# ğŸ“Š QDRANT FEATURES MENTIONED IN SCRIPT

| # | Feature | When Mentioned | Scene |
|---|---------|----------------|-------|
| 1 | Multi-Collection | "THREE specialized collections" | 5 |
| 2 | HNSW Tuning | "m=16, ef_construct=200" | 5 |
| 3 | Named Vectors | "THREE embedding vectors" | 4 |
| 4 | Sparse Vectors | "BM25-style term frequency" | 4, 7 |
| 5 | Hybrid Search | "Dense + sparse" | 7 |
| 6 | RRF Fusion | "1/(k + rank) with k=60" | 7 |
| 7 | Payload Filtering | "BEFORE vector search" | 6 |
| 8 | Scroll API | "Analytics dashboard" | 12 |
| 9 | Discovery API | "Recommendations" | 14 |
| 10 | Source Traceability | "source_email_id" | 8, 13 |
| 11 | Collection Info | "Metrics computation" | 12 |
| 12 | DatetimeRange | "Event dates" | 9 |
| 13 | API Key Auth | "Secure access" | 1, 14 |
| 14 | Idempotency Check | "Skip duplicate processing" | 13 |

---

# ğŸ¯ KEY PHRASES TO MEMORIZE

These phrases demonstrate Qdrant expertise. Use them naturally:

1. **"m controls graph connectivity, ef_construct controls index build quality"**
2. **"Reciprocal Rank Fusion with the formula 1/(k+rank) where k=60"**
3. **"Named vectors for multi-representation â€” title for precision, full_text for recall"**
4. **"Payload filtering happens BEFORE vector search"**
5. **"Scroll API for efficient iteration without expensive full retrievals"**
6. **"Every point stores source_email_id â€” zero hallucination, full provenance"**
7. **"BM25-style term frequency with hashing trick for sparse vectors"**
8. **"The vector database IS the product"**
9. **"Qdrant runs with API key authentication for secure access"**
10. **"Idempotency check via source_email_id prevents duplicate processing"**
11. **"Four containers, one command: docker compose up"**

---

# ğŸ“‹ PRE-RECORDING CHECKLIST

### Environment Setup (Docker â€” Recommended)
```bash
# Create .env file in project root with:
QDRANT_API_KEY=your_secure_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
DEMO_MODE=true

# Start all services
docker compose up --build -d

# Verify all containers are running
docker ps
```
- [ ] All 4 containers running: `feedprism-qdrant`, `feedprism-backend`, `feedprism-frontend`, `feedprism-lamatic-bridge`
- [ ] Browser open to `http://localhost` (port 80)
- [ ] Backend API accessible at `http://localhost:8000`
- [ ] Lamatic Bridge accessible at `http://localhost:8001`

### Alternative: Local Development Setup
```bash
# Terminal 1: Qdrant
docker run -p 6333:6333 -e QDRANT__SERVICE__API_KEY=your_key qdrant/qdrant

# Terminal 2: Backend
cd feedprism_main
uv run uvicorn app.main:app --reload --port 8000

# Terminal 3: Frontend
cd frontend
npm run dev
```
- [ ] Browser open to `http://localhost:5173`

### Demo Data Setup
- [ ] Demo mode automatically uses sample data (DEMO_MODE=true)
- [ ] If needed, reset demo state via Settings or API call
- [ ] Ensure 6 demo emails show as "unprocessed"

### Recording Setup
- [ ] Screen recording ready (OBS, QuickTime, Loom)
- [ ] Microphone tested and levels good
- [ ] Browser at 100% zoom
- [ ] No notifications (Do Not Disturb mode)
- [ ] Close unnecessary tabs/apps
- [ ] Terminal ready to show `docker compose up` or `docker ps`

### Script Prep
- [ ] Read through script 2-3 times
- [ ] Practice the demo flow without recording
- [ ] Time yourself (aim for 6-7 minutes)
- [ ] Note any tricky transitions

---

# ğŸ“¹ RECORDING SPECS

- **Duration:** 6-7 minutes (comprehensive with Docker + Lamatic)
- **Resolution:** 1920x1080 minimum (4K preferred)
- **Format:** MP4, H.264
- **Audio:** Clear voiceover, no background music
- **Upload:** YouTube (unlisted) or Loom
- **Include link in README.md and submission form**

---

# ğŸ† JUDGING CRITERIA ALIGNMENT

| Criteria | How We Address It |
|----------|-------------------|
| **Qdrant Usage** | 14 features explicitly demonstrated and explained |
| **Technical Depth** | HNSW params, RRF formula, payload filtering, API key auth |
| **Real Problem** | Email overload â€” universal pain point |
| **Production Quality** | Docker Compose, Nginx, SSE streaming, error handling |
| **Memory Focus** | "Vector database IS the product" â€” retrieval, not generation |
| **Innovation** | Hybrid search, multi-collection, source traceability, idempotency |
| **Demo Quality** | Complete walkthrough with 14 scenes covering every feature |
| **Lamatic Integration** | Dedicated bridge service for webhook-based processing |
| **Deployment Ready** | Single `docker compose up` starts entire stack |

---

# ğŸ³ DOCKER ARCHITECTURE SUMMARY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FeedPrism Docker Stack                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   Frontend      â”‚     â”‚   Backend       â”‚                   â”‚
â”‚  â”‚   (Nginx)       â”‚â”€â”€â”€â”€â–¶â”‚   (FastAPI)     â”‚                   â”‚
â”‚  â”‚   Port 80       â”‚     â”‚   Port 8000     â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                   â”‚                             â”‚
â”‚                                   â–¼                             â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                          â”‚    Qdrant       â”‚                   â”‚
â”‚                          â”‚  (Vector DB)    â”‚                   â”‚
â”‚                          â”‚  Port 6333      â”‚                   â”‚
â”‚                          â”‚  + API Key Auth â”‚                   â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                   â”‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚                             â”‚
â”‚  â”‚ Lamatic Bridge  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚  â”‚   Port 8001     â”‚                                            â”‚
â”‚  â”‚ (Webhook Recv)  â”‚                                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Container Details:
| Container | Image | Port | Purpose |
|-----------|-------|------|---------|
| `feedprism-qdrant` | `qdrant/qdrant:latest` | 6333, 6334 | Vector database with persistent storage |
| `feedprism-backend` | Custom (Python 3.11) | 8000 | FastAPI extraction & search API |
| `feedprism-frontend` | Custom (Node + Nginx) | 80 | React app served via Nginx |
| `feedprism-lamatic-bridge` | Custom (Python 3.11) | 8001 | Lamatic webhook receiver |

### Environment Variables:
```bash
QDRANT_API_KEY=...        # Shared secret for Qdrant auth
OPENAI_API_KEY=...        # For LLM extraction
DEMO_MODE=true            # Enable demo data
```

---

*You've got this. The technical depth is there. The product is solid. The architecture is production-ready. Now show the judges exactly what you built.* ğŸš€
